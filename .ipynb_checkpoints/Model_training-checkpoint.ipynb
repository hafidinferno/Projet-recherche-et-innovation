{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Chemin vers les répertoires d'images et de masques\n",
    "repertoire_images = \"./data_img/images/\"\n",
    "repertoire_masques = \"./data_mask/mask/\"\n",
    "\n",
    "# Liste des noms de fichiers dans chaque répertoire\n",
    "noms_images = os.listdir(repertoire_images)\n",
    "noms_masques = os.listdir(repertoire_masques)\n",
    "\n",
    "# Assurez-vous que les noms correspondent\n",
    "assert set(noms_images) == set(noms_masques)\n",
    "\n",
    "# Créez une liste de chemins complets pour les images et les masques\n",
    "chemins_images = [os.path.join(repertoire_images, nom) for nom in noms_images]\n",
    "chemins_masques = [os.path.join(repertoire_masques, nom) for nom in noms_masques]\n",
    "\n",
    "print(len(chemins_images))\n",
    "print(chemins_masques)\n",
    "\n",
    "# Créez un dataset à partir des chemins des images et des masques\n",
    "dataset = tf.data.Dataset.from_tensor_slices((chemins_images, chemins_masques))\n",
    "\n",
    "# Définissez une fonction pour charger et prétraiter les données\n",
    "def charger_et_pretraiter(image_path, masque_path):\n",
    "    # Chargez l'image et le masque\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_image(image, channels=3)\n",
    "    image = tf.image.resize_with_pad(image, target_height=256, target_width=256)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "    masque = tf.io.read_file(masque_path)\n",
    "    masque = tf.image.decode_image(masque, channels=1)\n",
    "    masque = tf.image.resize_with_pad(masque, target_height=256, target_width=256)\n",
    "    masque = tf.cast(masque, tf.float32) / 255.0\n",
    "\n",
    "    return image, masque\n",
    "\n",
    "\n",
    "# On charge et prétraite le dataset\n",
    "dataset = dataset.map(charger_et_pretraiter)\n",
    "\n",
    "def normaliser_images_masques(image, masque):\n",
    "    \n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "\n",
    "    return image, masque\n",
    "\n",
    "\n",
    "dataset = dataset.map(normaliser_images_masques)\n",
    "\n",
    "\n",
    "# print(dataset.element_spec)\n",
    "\n",
    "# for batch in dataset.take(1):\n",
    "#     print(batch[0].shape)\n",
    "\n",
    "\n",
    "# for image, masque in dataset.take(1):\n",
    "#     print(\"Forme de l'image :\", image.shape)\n",
    "#     print(\"Forme du masque :\", masque.shape)\n",
    "#     plt.subplot(2,1,1)\n",
    "#     plt.imshow(image)\n",
    "#     plt.subplot(2,1,2)\n",
    "#     plt.imshow(masque)\n",
    "    \n",
    "\n",
    "dataset = dataset.batch(8)\n",
    "\n",
    "dataset_size = dataset.cardinality().numpy()\n",
    "\n",
    "# Taille de votre ensemble de validation (20%)\n",
    "validation_fraction = 0.2\n",
    "validation_size = int(validation_fraction * dataset_size)\n",
    "\n",
    "# Validation\n",
    "dataset_validation = dataset.take(validation_size)\n",
    "\n",
    "# Entrainement\n",
    "dataset_train = dataset.skip(validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def unet_model_with_pretrained_encoder(input_shape=(256, 256, 3), base_model=None):\n",
    "\n",
    "    if base_model is None:\n",
    "        base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Congeler les poids de l'encodeur\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Prendre la sortie de la dernière couche de l'encodeur\n",
    "    encoder_output = base_model.get_layer('block4_conv4').output  # Modifier cette ligne\n",
    "\n",
    "    # Extensions (décodeurs)\n",
    "    \n",
    "    pool4 = MaxPooling2D((2,2), padding='same')(encoder_output)\n",
    "    \n",
    "    conv5 = Conv2D(16, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(16, 3, activation='relu', padding='same')(conv5)\n",
    "    conv5 = Conv2D(16, 3, activation='relu', padding='same')(conv5)\n",
    "    conv5 = Conv2D(16, 3, activation='relu', padding='same')(conv5)\n",
    "    pool5 = MaxPooling2D((2,2), padding='same')(conv5)\n",
    "    \n",
    "    conv6 = Conv2D(32, 3, activation='relu', padding='same')(pool5)\n",
    "    conv6 = Conv2D(32, 3, activation='relu', padding='same')(conv6)\n",
    "    conv6 = Conv2D(32, 3, activation='relu', padding='same')(conv6)\n",
    "    conv6 = Conv2D(32, 3, activation='relu', padding='same')(conv6)\n",
    "    \n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(16, 3, strides=(2,2), padding='same')(conv6), conv5], axis=-1)\n",
    "    conv7 = Conv2D(64, 3, activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(64, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(512, 3, strides=(2,2), padding='same')(conv7), base_model.get_layer('block4_conv3').output], axis=-1)\n",
    "    conv8 = Conv2D(64, 3, activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(256, 3, strides=(2,2), padding='same')(conv8), base_model.get_layer('block3_conv4').output], axis=-1)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    up10 = concatenate([Conv2DTranspose(128, 3, strides=(2,2), padding='same')(conv9), base_model.get_layer('block2_conv2').output], axis=-1)\n",
    "    conv10 = Conv2D(128, 3, activation='relu', padding='same')(up10)\n",
    "    conv10 = Conv2D(128, 3, activation='relu', padding='same')(conv10)\n",
    "    \n",
    "    up11 = concatenate([Conv2DTranspose(256, 3, strides=(2,2), padding='same')(conv10), base_model.get_layer('block1_conv2').output], axis=-1)\n",
    "    conv11 = Conv2D(256, 3, activation='relu', padding='same')(up11)\n",
    "    conv11 = Conv2D(256, 3, activation='relu', padding='same')(conv11)\n",
    "    \n",
    "    # Couche de sortie\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv11)\n",
    "\n",
    "    # Création du modèle\n",
    "    model = tf.keras.Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Création du modèle U-Net avec VGG16 comme encodeur pré-entraîné\n",
    "model_with_pretrained_encoder = unet_model_with_pretrained_encoder()\n",
    "\n",
    "# Affichage de la structure du modèle\n",
    "model_with_pretrained_encoder.summary()\n",
    "\n",
    "model_with_pretrained_encoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_with_pretrained_encoder.fit(dataset_train,\n",
    "                                            validation_data=dataset_validation,\n",
    "                                            epochs=50,\n",
    "                                            steps_per_epoch=2000,\n",
    "                                            callbacks=[early_stopping])\n",
    "model_with_pretrained_encoder.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pour visualiser le training plot\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.grid()\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.grid()\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
